---
title: "Notice du démonstrateur"
author: "Antoine Buvat / Julien Langevin / Michael Walter"
date: "27/09/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Ce démonstrateur comporte 5 pages. Pour chacunes d'entre elles, vous trouverez les éxplications ci-dessous.

##Comment utiliser ce démonstrateur

Page d'acceuil. Cliquez sur le boutton pour arriver sur cette notice.

## Qu'est ce qu'un SVM?

Si vous n'avez pas de notion en therme de machine learning, nous vous expliquons ici brievement la méthode de machine à vecteur de support.Cette courte introduction est inspiré du cours de Christophe Horlin, que vous pouvez retrouver en inégralité en cliquant ici(mettre un lien).

## Présentation de nos données

Vous trouverez ici toutes les informations sur les données que nous avons utilisées pour construire ce démonstrateur. Vous pouvez retrouver la base de données sur le cite de kaggle, en cliquant ici(mettre le lien).

##Intéraction avec le SVM

Ici, on montre les matrices de confusions sur l'échantillion d'apprentissage et sur l'échantillion test (les obsérvations bien classées sont en bleu, les autres en oranges), la sensitivité, la spécificité et le taux d'erreur qui leurs sont associées, ainsi que la courbe ROC obtenu par la méthode du SVM.  
Cette page est intéractive. Ainsi, vous pouvez choisir:  
**La fonction noyeau** qui permettra de rendre l'échantillion linéairement séparable (linéaire, polynomial, radial ou sigmoïde).    
**Le coût de pénalisation**, que l'on peut fixer à 1,3,5 ou 10. Pour rappel, plus ce dernier est important, plus on fait d'erreur, plus il est grand, plus on risque de faire de l'overfeeting. 
Si on choisis la fonction noyeau polynomial, on doit également fixé le nombre de degrées du polynome (3,4 ou 5)

##Comparaison du SVM avec les autres méthdes de machines learning

Cet ongltes se compose de 3 artie distincte:  

#Recherche du meilleur SVM

Page d'introdcuction de l'onglet. On explique brievement  la comparaison des méthodes.

#Régression logistique

On compare les résulats du SVM à ceux de la régréssion logistique.

#Arbre de régression

On compare les résultat du SVM à ceux de l'arbre de régression


